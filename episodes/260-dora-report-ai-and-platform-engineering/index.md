---
title: "Special: The DORA 2025 Critical Review"
description: "Dorota, CEO of Authress, guides us on the adventure to roast the 2025 DORA report â€” Focusing what productivity really means, the impact to our organizations, and who AI is really for."
image: ./post.png
date: 2026-01-02
custom_youtube_embed_url: https://youtu.be/WGZKoCHyC2A
---

import GuestCallout from '@site/src/components/guestCallout';
import GuestImage from './guest.jpg';
import BrandImage from './brand.jpg';

<div style={{ display: "flex", justifyContent: 'space-around', alignItems: 'center', flexWrap: "wrap", maxWidth: '100%'  }}>
    <GuestCallout name="Dorota Parad" link="https://www.linkedin.com/in/dorota-parad" image={GuestImage} brandImg={BrandImage} />
</div>

"Those memes are not going to make themselves."

Dorota, CEO of [Authress](https://authress.io), joins us to roast the 2025 DORA Report, which she argues has replaced hard data with an AI-generated narrative. From the confusing disconnect between feeling productive and actually shipping code to the grim reality of a 30% acceptance rate, Warren and Dorota break down why this year's report smells a lot like manure.

We dissect the massive 142-page 2025 DORA Report. Dorota argues that the report, which is now rebranded as the "State of AI-Assisted Software Development", feels less like a scientific study of DevOps performance and more like a narrative written by an intern using an LLM prompt. The duo investigates the "stubborn results" where AI apparently makes everyone feel like a 10x developer, where the hard results tell a different story. AI actually increases software and product instability â€” failing to improve.

The conversation gets spicy as they debate the "pit of failure" that is feature flags (often used as a crutch for untested code) and the embarrassing reality that GitHub celebrates a mere 30% code acceptance rate as a "success." Dorota suggests that while AI raises the floor for average work, it completely fails when you need to solve complex problems or, you know, actually collaborate with another human being.

In a vivid analogy, Dorota compares reading this year's report to the Swiss Spring phenomenon â€” the time of year when farmers spray manure, leaving the beautiful landscape smelling...unique. The episode wraps up with a reality check on the physical limits of LLM context windows (more tokens, more problems) and a strong recommendation to ignore the AI hype cycle in favor of a much faster-growing organism: a kitchen countertop oyster mushroom kit.

## ðŸ’¡ Notable Links:
* [AI as an amplifier truism fallacy](https://www.kentarotoyama.org/papers/Toyama%202011%20iConference%20-%20Technology%20as%20Amplifier.pdf)
* [DORA 2025 Report](https://dora.dev/research/2025/dora-report/)
* [DevOps Episode: VS Code & GitHub  Copilot](https://adventuresindevops.com/episodes/2025/10/31/managers-of-agents-ai-strategy)
* [Where is the deluge of new software](https://mikelovesrobots.substack.com/p/wheres-the-shovelware-why-ai-coding) - [Impact of AI on software products](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/)
* [Impact of AI on Critical Thinking](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/01/lee_2025_ai_critical_thinking_survey.pdf)

## ðŸŽ¯ Picks:
* Warren - [The Maximum Effective Context Window](https://www.arxiv.org/pdf/2509.21361)
* Dorota - [Mushroom Grow Kit](https://amzn.to/4pMIkr9)