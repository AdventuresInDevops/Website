---
custom_slug: infrastructure-as-code-using-llms-and-critical-thinking
hide_table_of_contents: true
title: "The Open-Source Product Leader Challenge: Navigating Community, Code, and Collaboration Chaos"
description: "Pulumi's GM Meagan Cojocar tackles the product leader's journey, the future of open source, her experience at AWS versus Pulumi, and the philosophical debate around LLMs in DevOps."
image: ./post.jpeg
date: 2025-08-24
custom_youtube_embed_url: https://youtu.be/K_ltF1rRV7M
---

import GuestCallout from '@site/src/components/guestCallout';
import GuestImage from './guest.jpg';
import BrandImage from './brand.jpg';

<GuestCallout name="Meagan Cojocar " link="https://www.linkedin.com/in/meagancojocar/" image={GuestImage} brandImg={BrandImage} />

In a special solo flight, Warren welcomes Meagan Cojocar, General Manager at [Pulumi](https://www.pulumi.com/) and a self-proclaimed graduate of ‚ÄúPM school‚Äù at AWS. They dive into what it's like to own an entire product line and why giving up that startup hustle for the big leagues sometimes means you miss the direct signal from your users. The conversation goes deep on the paradox of open-source where direct feedback is gold, but dealing with license-shifting competitors can make you wary. From the notorious HashiCorp kerfuffle to the rise of OpenTofu, they explore how Pulumi maintains its commitment to the community amidst a wave of customer distrust.

Meagan highlights the invaluable feedback loop provided by the community, allowing for direct interaction between users and the engineering team. This contrasts with the "telephone game" that can happen in proprietary product development. The conversation also addresses the recent industry shift and then immediate back-peddling from open-source licenses, discussing the subsequent customer distrust and how Pulumi maintains its commitment to the open-source model.

And finally, the duo tackles the elephant in the cloud: LLMs, and extends on the earlier [MCP episode](https://adventuresindevops.com/episodes/mcp-servers-and-agent-interactions/). They debate the great code quality vs. speed trade-off, the risk of a "botched" infrastructure deployment, and whether these models can solve anything more than a glorified statistical guessing game. It's a candid look at the future of DevOps, where the real chaos isn't the code, but the tools that write it. The conversation concludes with a philosophical debate on the fundamental capabilities of LLMs, questioning whether they can truly solve "hard problems" or are merely powerful statistical next-word predictors.

## Notable Links
* [Veritasium - the Math that predicts everything](https://www.youtube.com/watch?v=KZeIEiBrT_w)
* Fact - [Don't outsource your customer support: Clorox sues Cognizant](https://arstechnica.com/security/2025/07/how-do-hackers-get-passwords-sometimes-they-just-ask/)
* [CloudFlare uses an LLM to generate an OAuth2 Library](https://neilmadden.blog/2025/06/06/a-look-at-cloudflares-ai-coded-oauth-library/)

## üéØ Picks:
* Warren - [Rands Leadership Community](https://randsinrepose.com/welcome-to-rands-leadership-slack/)
* Meagan - [The Manager's Path by Camille Fournier](https://amzn.to/48SfvnA)