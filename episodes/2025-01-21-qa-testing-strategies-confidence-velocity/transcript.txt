Um, oh, there we go. It's always great when the episode starts with me going, uh, that editor, but he gets rid of that. I hope so. If not, we'll hear about it. So welcome everyone to another episode of adventures in dev ops. Happy new year, Warren. Happy new year. Thanks for joining me today. Oh, thank you for having me back. Always a pleasure. Jillian. Welcome back. How are you? Good, good. How are you? And Happy New Year. I'm doing well. I'm pretty excited about today's episode because we have your background, AJ. So our guest today is AJ Funk and his background is just so cool. So you're a... software engineer for Rainforest. You live in California, you're a snowboarder, and you are a previous D-I and professional baseball player. Is that all correct? That is correct. I've taken an interesting career path. So yeah, definitely lots of stuff to do here. And I'm in the Lake Tahoe area in California, right on the border of California and Nevada. So yeah, it's all true. What position did you play in baseball? I was a pitcher. A pitcher. Okay, cool. Oh, that's what I know what it is. I was about to be like, I have no idea what we're talking about here, but I know what the pitcher is. It's all about the little connections, Jillian. It really is. So cool. AJ, tell us a little bit about your role at Rainforest and what Rainforest does. And I think I'm interested to hear what led you to go from pitching Major League Baseball to pitching code. Yeah, for sure. Yeah, so I started writing code when I was a kid, really, always as a hobby. My plan in life was always to play baseball. You know, once you become an adult and you realize that it's not always such a viable career path, I started realizing that this thing I do as a hobby I could do as a career. So just started kind of dabbling and realizing that I actually really enjoyed doing this. And it was a big pivot from just athletics all the time. So yeah, now I ended up at Rainforest QA. I've been here for seven and a half years now. Oh, wow. Yeah, it's been a long time, and it's been really fun. I work with really, really great people, really intelligent, experienced engineers, really great culture. We're distributed all over the world, so it's fun. We get to go meet up with each other every once in a while in some random place in the world. And so it's a really enjoyable place to work. I specialize in front-end development, so I spend a lot of time with the product and design team shaping how our product works. And as a quality assurance company, it's really important for us to have a really high bar of quality and reliability for our product. Obviously, if our app breaks, why are you going to trust us to make sure that your app doesn't break? Seems reasonable. Yeah, right? And to meet that high bar, we use Rainforest to test Rainforest. So being able to eat your own dog food on a daily basis is a really, really good position to be in. It allows you to identify pain points in the user experience before your users do. Hopefully, that's not always true, but we do our best. And it also means we spend a lot of time thinking about the best way to do QA, both from a kind of philosophical standpoint and from a practical implementation standpoint. reality in other words um so this experience obviously helps guide our product roadmap but it's also led me to develop a lot of strong opinions on how product and engineering teams should shape their testing strategies what kind of tools they should be using and how they can ship code quickly and continuously without having to sacrifice quality sure for me that seems like one of those um rabbit holes that it's really hard to find the balance on of like what's the minimum level of testing that you should be doing and then like what's a what's an adequate level to get into where you're actually still getting good use for your time you know because obviously you can throw something at it that tests every possible combination or path through your application that could ever be taken. And you're going to reach a point of diminishing returns there. So how do you figure out what that right spot is? Yeah, absolutely. The myth of a hundred percent test coverage, right? That we all strive for. I think they teach you very early on that like a hundred percent test coverage is What we should be doing with every time we push code there, we should make sure everything is covered. The reality is that's just not possible, right? What does that even mean? Does that mean every line of code is covered? Does that mean every possible edge case is covered? Like you're never going to get all of those things. So the trick is finding that balance, right? We want to make sure that we have... confidence in the thing that we're shipping, that both the thing we're shipping works and that we're not breaking anything else. But we also want to be able to move quickly. We don't want this to get into our way. And so The main ways we go about that is really thinking about what your testing strategy is. What are you testing? What is your bar for quality? Because in reality, sometimes we're okay if some things break, especially when we're in the early stages of prototyping something, it's a beta feature, et cetera. what are the layers of your testing, right? So we can think about our testing strategy as layers with, pictured as three layers, but more as a period, right? So your foundation of your testing strategy is your unit tests. This is something we're all familiar with. We're using code to test code in small chunks, right? What a unit is, is totally up to you. We can define it as a single function or some class component, whatever. The top of our pyramid is our end-to-end or our UI tests. um that's testing our application in a kind of real world scenario as we go up the pyramid these tests are more comprehensive we can rely on them more but they're slower they're more expensive right so at the base of our pyramid we have all of these unit tests that we could run constantly so rainforest we run these every single time you push code it just runs them because it's cheap we don't really care if you're lazy like me I like to just push my code up and oh something broke I didn't notice because I don't want to run the whole test suite all the time on my local machine But as you move up that pyramid from unit tests, the middle of that pyramid would be our integration test. So basically testing multiple chunks of these units and how they interact with each other. That could be maybe one of your microservices talking to another microservice or something like that. as we get to the top of the pyramid and we start running these end-to-end tests that's where I think strategy becomes much more important because like I mentioned they're slower so we actually care about when we run these we need to be more strategic about how often we run them um and they are more expensive so we don't want to just blow a bunch of a whole bunch of money on them right right so finding the balance between those things is the real trick I like that you pulled out test pyramid and not one of the other newer hipster trends of the test diamond or a test Klein bottle. The tried and true test pyramid. I mean, at least that's how I've always seen it. And it's also really interesting that you bring up the a hundred percent test coverage is not possible. At least from like anecdotal experience for me, I found it's almost like a Pareto distribution and follows the eighty twenty rule where if you wanted to have a hundred percent test coverage, it would actually require an infinite amount of time. Absolutely. Yeah, we certainly strive to have all that test coverage, but I think the reality of a hundred percent test coverage is more along the lines of how you define like your user workflows, right? So the typical example is like your login flow. What are the main outcomes of the login? It's successful login, failed login, maybe it forgot your password. And do you have test coverage, end-to-end test coverage on that flow? If so, we could usually consider that covered. Do I have a unit test that covers every combination of things that I could type into that box? Absolutely not. But having some sort of test coverage on it to make sure that it actually loads in some kind of real-world scenario gives me much more confidence. With a lot of things like logins, and there's so many areas these days in developing software, you're using SaaS products as the mechanism for implementing that. What's your approach for dealing with that external dependency? Because you can mock it or you can try to simulate it or you can actually call it. What do you think about those? I feel like there's a jab at me, Will. I see you coming there. No, no, I'm trying to... Yeah, I got nothing. AJ, back to you. Yeah, so I think what you're asking is when we run any kind of tests, we'll stick with unit tests for the time being, there's a context that they run inside of, right? If we wanted to test our app as close as possible to reality, we would test it in production on an actual machine with an actual human, which some people do, right? There's obviously downsides to that. Testing in production, probably don't have to get into why that's not a great idea. And... The entire video game industry is wrong? Like, how are you testing things? Touche. And yes, they are wrong. I mean, I'm not even sure that's true anymore. They don't even release games, right? It's just content that you click download on and you pay for, and then the game comes later or something. I think that's what the game industry has gone towards. That does kind of be how it goes, but I still feel like they have the users doing an awful lot of acceptance testing in the video game industry. And I'm too cheap for this nonsense. But anyways, I'm trying not to derail the entire conversation today. so we can we can skip right on over that no I I totally agree and it's like you do even when you do get a game it's an incomplete game that's buggy and you play it for an hour and you go I'm never playing this again um so I'm I'm a late adopter when it comes to these things I wait till I uh the internet stops screaming about it and then I start downloading things But yeah, obviously we don't want to test our applications in production because we're smarter than that and we have the ability to test these things in different environments. When we are running things like unit tests, we're kind of stuck inside of this artificial context, right? If you're just running code to test code, it's inside of that specific code environment. It's giving us inputs and outputs, even as we go up the chain to some things that like to call themselves end to end tests, which I kind of disagree with, which would be things like Dom based testing. You're still stuck inside some kind of context, right? So for the the Dom, if you're not familiar, it's the document object model, and it's essentially the. application interface that we have with the browser. So that's how our JavaScript code talks to the browser. how we manipulate things, how we read things from the browser. And so the important nuance here is that our code interacts with the DOM. A human being doesn't interact with the DOM, right? When you go click a button, you don't go talk to the DOM, you interact with the user interface. So we want to get our tests as close to actual end-to-end tests as possible, right? A human looking at the screen, a human interacting with the screen. If we're not in that production environment, every step we take away from that gets us further from reality, right? It gives us this false sense of security sometimes. There's a really common example with DOM-based tools might be click this button, did it work, right? well just because you can interact with that button through the dom doesn't mean your user can actually interact with that button right there might be um you know some kind of overlay over my button the button might be off of the screen but when I asked the dom can I click the button it says yeah we clicked it it worked ship the code and now no one can log into your app because no one can click the button right um and so doing our um as much as we can to get to that real world scenario, creating testing and staging environments that mirror production as much as possible and loading these things into virtual machines with operating systems instead of a headless browser, which is basically a browser with no UI and interacting with it in a way that a human doesn't interact with it just gets us further away from reality. I mean, it's interesting you bring that up and I'm sort of, now I'm intrigued if you maybe want to roast what we've been telling our customers. So obviously we provide a third party product for our customers for login and access control. So they have, you know, providing them the auth needs there. And I think the biggest advice that we end up giving them is like, We are already testing that thing. Don't focus on this. You're wasting your time duplicating our testing. If you felt the need to do that, it's almost like you don't trust us with our product. And then you probably should question why you're using that solution in the first place. If you get to that point, that's actually a conversation more than it's a technical solution. However, we do find some customers still have a need to go a little bit further. And the thing that we've done, I don't know if this is the right answer, but we provide a, given it is a SaaS product, we provide a clone of our service as a container that can run that is trimmed down only has uh minor features but allows the flows that you're going to test or you want to actually verify uh available without having to go through all the complexity that the service actually provides yeah I mean I think that's a good compromise right so in in this whole strategy of finding balance between our our confidence and and our velocity and shipping um The reality is our testing environments are not going to match our production environments all the time, right? And a lot of times we're constrained by resources. So I think in a situation like that, that totally makes sense. Some kind of pared down version of your production application. I think the important thing is how you're testing it, right? If we are able to just kind of like strip down our product and test the bare bones version of it, as long as we are in an environment, right? They're clicking on it through, I don't know, a web browser or whatever it might be versus just like running some script in the background. I think that's a really good balance between those two things. The key here is that we're still doing end-to-end testing, right? I imagine it's, you know, that someone's typing in the box, a button's being clicked, there's an HTTP request or whatever it might be to an API that reads from a database, and we're checking that all of these things actually work together. So yeah, I think that's a good compromise. I think one of the things that actually comes up a lot is, maybe just on a slight tangent, is people are so focused on end-to-end testing, they never stop to question, should we? Like for that particular flow, is that where the value is for our company? Is it really where we should put a lot of resources in? Do you find that those that you're working with or your customers may or may not know where the highest value testing should be done. And then that's a conversation or maybe it's something that your tool provides. Yeah, absolutely. And I think the trick for that is doing it early, right? So, if you have a large application in a code base and you have not written any end-to-end tests, it's hard to determine where to start, right? Versus if you start early on, it kind of writes itself, right? The first thing is your login, you have some login coverage. Determining where the highest value is is certainly up to each, usually the product team, right? What do we care most about not breaking? And can we create some kind of smoke test that spans all of these, right? So each one of these tests has a certain level of granularity to it. A good smoke test might be. Can I log into my application? Can I create a thing? Can I delete a thing and things just like generally work? Those initially are your highest value tests because I know that my app actually loads in reality, right? Regardless of what my unit tests say after that. it's usually defined by what those user flows are. So as you're scoping something out with your product team, here's this new feature that we're building. It's really important in your planning process to include that. Write tests for it. These are things that we usually as developers kind of bake into our estimates right I have to write unit tests for this at rainforest we've shifted more towards baking and rainforest tests for these things we obviously have unit tests but getting the coverage at the time of implementation or the time of release or whatever that might be is usually your best bet to get that If I have a large application and I don't have that coverage yet, it is certainly a balancing act figuring out what should we test first, right? So I would certainly start with those kind of smoke tests. And then your highest used features is usually a really good place to start. The pitfall that you go into is putting too much nuance in a lot of these tests, right? What if they click into this and click out of that and then open this menu and whatever, keeping them very coherent and legible and kind of focused on the thing that they're testing is the important piece of having efficient tests that you can maintain. I saw Will smirking there, and I know he's just entered into a new glorious position at his organization. So maybe he has some unique insight that he's interested in blessing us with. No, I was curious because this is an opportunity for me to throw in a buzzword that's trending. And so once the episode is transcribed, we'll just go viral on that. So does AI play a role in helping figure out that type of user flow in the different like odd places you can end up? Good question. Not to my knowledge yet. AI is really good at some things and really bad at some things. And we haven't quite figured out how to give it enough context to understand how it should go about testing your app. We do have some really cool AI tools at Rainforest. determine what your test coverage should be. Rather, that's kind of left up to you, and then it helps you write the test. So what we have is entering a prompt. Say it could be something pretty generic. Log in and add an item to the cart and checkout, something like that. And it will generate your rainforest steps for you. So during execution, AI is left out of it. It does the initial generation, and then we just execute things normally. And then we have some self-healing functionality. So it fails on something that we generated. We're going to try and regenerate those steps. And what's really nice about that is since Rainforest is a visual tool, we identify things on the screen based on screenshots. it's possible for you to make slight visual changes. And now that image doesn't quite match up. Your test might fail. You don't want to have to go back in and retake all of those screenshots. But since it's generated by AI, it could go back, follow the same steps, and realize this is what the button is here. It would be really cool if it could kind of add that test coverage for you or like tell you what you should be testing. We've poked at that a few times and it's honestly just really dumb in that aspect and doesn't really give you anything useful. It's like, yeah, go go test all the things and make sure things work. And it's like, cool. Yeah, I knew that. Thank you. Yes, they get smarter. I feel like part of the answer is also the domain you're in. I know something that we haven't talked about is like really at the top of the test pyramid is exploratory testing. Whereas like add your creative human instincts to where bugs could potentially pop up while you're looking at an interface or or API, and I don't think we're doing anything wrong in the creation of AI and LLM models. It's removing the creativity from them. And I think that that harms us here. But there has been one area, especially within things like protocol, protocol creation or SDKs interfaces for the services. And that's, I think the key word is fuzzing. So trying an LM, any sort of AI can spam with almost a more intelligent brute force strategy about what sorts of inputs tend to break your interface or your service or your product, and then use that as a potential test that you can commit longer term. And again, it's not for everything. Like, I don't think it really works so much in a UI world, but definitely depending on what your service or interface is doing, stuff in the crypto space, cryptography, not blockchain, just to be clear. I feel like that was a dig there, Warren. What are you trying to say? You know, it's not the sort of thing I want to bring up on an episode, Will. You don't want a record, huh? Yeah, definitely not on record. We do cryptography because we're really into security and deep there. And we're not building our own crypto, but we're very high users of it. Everything JWT creation or JWT creation, every single different kind of algorithm strategy, we end up utilizing these. And so finding where we're not using libraries effectively is certainly an area that we've potentially looked into. Actually, according to our company bylaws, we're not allowed to do anything regarding cryptocurrency. It's actually not allowed by the country of Switzerland for us to get involved in any way. We can't accept payments. We can't pay people in crypto. We can't even think about consulting for companies that want to do something crypto related. That's discrimination. I work in HPC and I'm pretty sure like some of the admins will just kind of use like a little bit of the compute power from different clusters that they have to be running different crypto schemes. But I haven't, I haven't like a hundred percent caught anybody, but I'm just, I'm waiting for the day. I'm waiting for it. Not to tell on them. I just want to know because I'm super nosy. I just like knowing things like this. You're not going to tell on them as long as they cut you in? Yeah, that's right. That's the scheme. It's like when my website got hacked by that Chinese jewelry store and I was like, guys, if you would just give me a cut, this would be fine. It was nice jewelry. I mean, I think that really is expert advice from our resident ML expert here because... Get in on the scheme? Well, yeah, I mean, Amazon... Yeah, no, because AWS just came out and said that the strategy of sharing reservations across customer AWS accounts, like if you're a consultant that does bundling for instance reservations or compute reservations, you no longer can pass along that savings to the customer. I mean, what are they going to do with all this excess capacity now other than some good old fashioned Bitcoin mining? I don't know I don't know I mean we could be making drugs for autoimmune diseases and cancer or or we could be making some cold hard cash I don't know you know it's not it's not an either or there's plenty of compute power these guys have you know they're spinning up plenty of aws things they're not going to notice if that last ten percent is using crypto So when this episode launches and we all get blocked from our respective AWS accounts, we can just reflect on this moment fondly. So, I mean, for the record, AWS isn't going to block you because the ROI on utilizing cloud resources to mine crypto is so low that you're pretty much just paying AWS. But it is a good indication that there is malicious activity happening on your account. So it is something that they will for sure investigate. And that I think is as much of a tangent on this that I want to go down for today. I think we should talk about the low code with Rainforest. I love low code stuff. How did this come about and how does it work? I want to know all about it. yeah for sure um so when I first joined rainforest over seven years ago our model was a bit different we had a bunch of human testers it was kind of the gig uber model of I have something I want to test here's my test cases they're all written in plain english and we'll provide a bunch of humans for you to to go test your application right including some exploratory stuff like you mentioned go click all over this page and try and find problems with it And that worked really well. It was true end-to-end testing. We load your app in a virtual machine inside of a web browser. They're actually clicking the buttons and confirming there's things on the screen. But what we found is that humans are inefficient and expensive, as we all know. That's why we have automation, right? And so we kind of shifted Over to automation, but we want to do something a bit different from what everyone else was doing, which is these code based tools, Dom based interactions, and instead we built it all on the visual layer. So the way it works is. you go in you load your app and uh you essentially just like take screenshots of things right click on this um type into this field uh I can give it an ai an ai prompt and say you know log in and check check out in the cart and then when you execute things it loads in the same environment right you have your your staging environment hopefully you have some um some seed data with login information. You can load that all in the rainforest. It goes in and runs this whole workflow for you. The output of it is a video of the thing being tested. Results on each step. Things like HTTP logs, JavaScript console logs, all the information that you need to actually debug things when something breaks instead of it just saying, you know, like in a unit test and it's like failure, like one does not equal two. And so by doing things at that visual level, it offers a lot of flexibility. The first thing is that we're not stuck inside of the browser, right? We do primarily focus on web-based testing, but that does not mean you're stuck inside of the browser. it means you can do things like install a Chrome extension, right? Open another tab in your browser, install a Chrome extension, interact with that extension because while you're still inside the browser, you're outside of the scope of that webpage where you usually are interacting just through the DOM. You can install some type of desktop application and test it through there because since we're working at the visual layer, it doesn't care what you're testing. It doesn't care what your tech stack is. It just cares that it loads in the machine. And it also offers a lot of more flexible and robust in avoiding flakiness and brittleness to small changes. We have fallback methods. As much as I've been kind of hammering that testing with the DOM is not a great idea, we do offer DOM fallbacks because sometimes it makes sense. Sometimes I don't care about the visual appearance of the button, and all I care about is that there's a button there, right? in reality, there are variables that we can't control, right? A very common scenario is my marketing team is running experiments. Every time I load this page, the button says something different. It looks different. And so we don't want to tie the visual appearance to the pass fail result of this test. So I'll use something else. I'll use a DOM selector. We also have like AI search. You could say something like the button, the login button at the bottom of the page. And so the important points here is you don't write any code whatsoever. We have an intuitive UI that you do all of this through, which means you don't need skilled engineers to do it. A lot of teams have QA engineers that their job is to just write tests all the time. Other teams, the engineer is responsible for writing these tests, but they need very specific domain knowledge. I need to know about the thing that I'm testing like from a product standpoint what does this thing do I need to understand the code I need to know how to write these tests with a no code solution anybody can do this right it's it's up to your team who owns quality who owns these tests for us it is usually the the engineer that is shipping the code we write the rainforest tests with it or our product and design team owns it because like I was saying They're very tied to our user workflows, right? They're like, this is how we designed this thing. Engineers are going to build it. And then any of us that have knowledge about how this user flow is supposed to work can own this test. So it makes it much easier to both write and maintain your tests over time. And then, you know, if that person leaves your company and has all of that domain knowledge on how it works, you just need someone who knows how the app works and they can update your test suite. Now, I feel like one of the biggest mistakes that I keep seeing over the course of my career is as companies grow, they tend to have more, allegedly more software, more code, which may or may not end up in a giant ball of mud mass or even an extensive number of quote unquote microservices that communicate and really depend on each other. there was always this challenge by someone who wanted to have a test that required somehow interacting with all of these components. And they never really could understand that one of the whole points of microservices was to isolate testing. But I think we live in the reality, which is there are some companies that do have a giant ball of mud that have thousands of binaries that have to be installed and running servers. Is there a strategy that, I don't mean to pick on your company. I don't know if there, I don't think there is a strategy. I think the strategy is write microservices, but I can imagine that, you know, as a SaaS company, the last thing we want to tell our customers is, yeah, have you tried not having that problem? Have you tried writing to your package manager? That tends to be the solution that I see. That one is everybody's favorite. Yeah, distributed monolith always works. Publish all your binaries that remotely depend on each other to a third party solution and then pull those out at runtime. Always works. Best solution ever. Maybe AJ, you have some insight here on either something that works or something that works with Rainforest QA to deal with those situations. Or maybe you just, you know, it's not something that is handled today. Yeah, for sure. We do have a bunch of different microservices running. And I think I'm going to refer back to the testing pyramid, right? Is we test each one of those microservices in isolation. Absolutely. Maybe we test as we go up to the next layer of our integration test, we test some interactions between them, right? The kind of core integration. you know, handshake interactions, whatever is the the main functionality of these two microservices talking to each other. Maybe we have some tests there. But at the end of the day, these end to end tests are comprehensive, right? If anything in that microservice architecture is failing, presumably my test is going to fail. And at the end of the day, all we really care about in theory is what the user gets when they're interacting with it. So if I'm just clicking a button, maybe there's a thousand microservices that are involved in this, and maybe I'm not directly testing each one of those. But by implementing it as an end to end test, I am very confident that they're all working because my test passed. And so being smart about how you implement each one of those layers in an efficient way, right? Lots of unit tests on each microservice and then this overarching test that just makes sure everything is working together is usually the way to go about this. I mean, maybe it's a technical implementation question. Like, where is the environment running that the Rainforest tests are actually executing? Is this some sort of binary or CLI that's run on the client side? Or are they sharing with you a set of microservices with deployment instructions so that you can run them within your own infrastructure? Sure, usually our requirement is that you need to be able to access it via a web URL. So the kind of standard way that a Rainforest test is run is we provide you a VM and that VM has a browser on it so I can specify Chrome on Windows. And the first step of your test is going to be a navigation. Navigate to this URL. This is where my web app lives. There are some different use cases where you can absolutely go download a binary and install it and do whatever you want with it. Our out of the box functionality is to primarily test those web apps. So that's where we focus, but you certainly have the flexibility to do whatever you want with those VMs. No, I mean, I think, I think that approach is genius. Basically it's out of scope for setting up the environment, unless you want it to be in scope of which, you know, then it's a, it's a virtual machine go to town on however you want to deal with it there. Right. And by kind of forcing people to give it a public URL, we're nudging them towards good practices, right? For sure. Set up a staging environment, a QA environment, and make it mirror production as much as possible, which includes being able to navigate to it in a URL. And these are small things that we see with some of our new clients are like, well, I don't have a staging environment. And sure, I guess you could load your production environment in there, but let's show you how to test this properly and not shoot yourself in the foot. I love that you're saying that. The number one feedback I've always seen here is we can't expose our non-production environment publicly. People can't know what we're currently working on. They will use that information maliciously against our company in some way. Yeah, like what are they gonna do with it though? I have seen some interesting mistakes, like maybe we're cloning our production database and not sanitizing sensitive information from it or something like that. Yes, absolutely, you're doing some bad things, but there are certainly ways to do this. And I'm of the opinion, who cares if people are in your testing environment, like worst case, they blow up your testing environment. whatever. And in that case, you figured out how they could blow up your production environment without losing prod. Exactly. Yeah. I think there's, um, That's, you know, like part of the undocumented learning curve of working in this industry, you know, because people who are early in their careers think things like, oh, I shouldn't expose staging until, you know, they learn that that's actually probably a good thing, but like nowhere in any computer science or course or bootcamp or anything, do they cover these kinds of things? And so I think that's actually like a really valuable add on service that you get from Rainforest or that you get from working with people who are more experienced is just like learning that tribal knowledge that's gonna help you out later in your career. So you don't have to reinvent the wheel and solve problems that we actually solved years ago. I mean, that's well, I mean, we've unfortunately had to append our documentation with like, here explicitly are the sensitive pieces of data that are relevant to our third party application. This is sensitive. This is sensitive. Like, this is not sensitive. This is like the application ID, not sensitive. Like, do not try to encrypt this. Do not try to secure it because people will try. Like, how do I do this? I'm like, you can't stop it. Like, this has to be public. on your website, in your application, people have to be able to see it. You're not going to get around that. And I feel like it's more than just experience. I feel like there's a whole level of pragmatism there, like weighing the cost versus the reward of actually trying to sanitize that piece of information. And having a third party testing service, as you mentioned, just reinforces that in a way like you are going to have to expose that to be tested, must show that it's not actually sensitive information. Yeah, definitely. To me, it just reminds me of the myth of the hundred percent test coverage, right? It's like, can we a hundred percent encrypt everything? Absolutely not. Your end users need to see this information. I've seen some interesting attempts to obfuscate those things. I've seen some libraries that prevent you from opening the JavaScript console, for example. And it's like, what are you hiding in there? Maybe you should just not put sensitive things in there. Here's a wild thought. How about you just don't do that? Do you have your credentials encoded in the HTML on your page? Maybe. I mean, I can't believe you two are joking about this, honestly. One of the most common attacks against AWS accounts. So I don't do UI, so I can joke about all this because none of this is worthwhile. It's okay. Absolutely none of this. I'm just like, uh-uh. Jillian, you'll have plenty of opportunity to get your models encoded with AWS Access Keys and Secrets, and then you just ask the model, hey, can I have an Access Key and Secret that are valid that work for any AWS account? I did actually accidentally push my AWS credentials to GitHub once, and the amount of emails that I got from AWS was just like... It was unreal. It was a very, it was a very bad day for me. It was a very, very bad day. So I've done other stupid things, but I don't do the same stupid thing. So I can sit here and be very smug about this, like this. That is like, that is, I've always, I've often wondered about that. Like the speed that AWS and other malicious people can identify that you committed an AWS access key to a GitHub repo. It was instant. It was like right then. Cause as soon as I did it, I was like, oh no. And tried to, you know, and like try to like make the GitHub repo private and nope, it was instant. They knew, they knew it was out there. Yeah, I mean, it's bad. I mean, I think I saw a bunch of statistics on this that for AWS keys and on GitHub, it's about thirty seconds to two minutes having been exposed in the repository anywhere in any format. So like commit at the beginning of the repository where It was there, but then got removed. So it's not in plain text anymore. You have to go back through the get history. It's still about two minutes. Then there's exposure on Stack Overflow and places like I don't know who uses Facebook in connection with their work, but that was another place. And then Instagram and Reddit are somewhere between two and four or five days. And then there's a couple other ones where it's six and more. Some of those you have to thank like GitHub for like they'll actually discover secrets there. So if you provide a third party application that has credentials like at authoress, we have our secret keys registered there. So if one of our customers exposes keys for our service on GitHub will get notified automatically revoke those keys and send them an email telling them that they did something that they probably did not want to do multiple times if that's if necessary, because that's happened as well. I want to switch topics here real quick, AJ, because you've been with Rainforest QA for over seven years now, which is unusual in the tech industry. So I'm curious about what are the things that you look for in a job that have been fulfilled at Rainforest that keep you there that long? Yeah, for sure. First and foremost is the people. Actually, when I was interviewing with Rainforest, the last person I talked to told me something like, I say it Rainforest because of the people. And I was like, okay, that's what everyone says. Oh, we're family, right? Yeah. And then I quickly drank the Kool-Aid, I think. And I found myself saying that on interviews. And I'm like, I know this sounds like a load of crap, but it's true. And I think the hiring process is super, super important, right? Yeah. Both finding people that are qualified for the job, obviously, but are good culture fits. We have a pretty small team, so there's nowhere to hide. If you are not doing your job or you're not up to par, you're going to be exposed pretty quickly, which leads us to have a very reliable team. We are distributed globally, so there's a lot of handoff. I'm going to sleep, you're waking up, here's what I did. And I trust when I wake up that you're just going to have this thing done. And if you're not one of those people, you're probably not going to fit at Rainforest. So really, really qualified, experienced, smart, reliable people makes life so much easier. And then the other piece of it is the mission that we're on, the technology that we're building. I think when I was first exposed to it, The first time I shipped code with Rainforest, it was kind of like, wow, how have I been shipping code before this? And the answer was I was probably breaking things all of the time. And you don't notice until user catches it in production two days later or whatever. It's something that I'm really passionate about. I think as a front-end engineer, we get really caught up on the details. There's all these visual layers. There's these very specific human interactions. I like building things that humans are actually interacting with. And that kind of naturally leads you to a quality assurance mindset, right? I want everything to be perfect all of the time. How do I ensure this? And so the combination of really great people and working on something that I'm actually really passionate about and I want to see the rest of the world adopt these correct ways of testing things, in my opinion, of course, just makes it makes it easy to work here. Yeah, right on. That's cool. That's cool. Is there you guys obviously do a lot of front end type testing? Is there a particular industry or vertical that you have got a lot of experience in or something that has worked really well that makes a really cool story? Something I've been involved in that makes a cool story. Ooh, I don't know if I have a good answer for you, honestly. Like I said, I've been at Rainforest for so long, that's all I can think about, I guess. Right. Do you attract a certain customers with financial apps or with web-based gaming apps, or is there a particular vertical that tends to gravitate towards your service? I think not really. And I think that's one of the things that makes it cool is it's a very generic testing tool, right? There are some limitations. But in general, if you could load your app on a machine, you could probably test it with Rainforest, not caring about what the tech stack is, those kinds of things. So there's a very wide range of users that we have from, yeah, there's some financial companies. doing some what I always find interesting, kind of like testing visually things like spreadsheet style apps, like their tables and things like that. And then we have some really cool like visual tools, like drag and drop interfaces where you're building things like, you know, Lego style building where there's probably, to my knowledge, not any other great way to test something like that. Like, what do you say? Are all my Legos on the page? Yeah, they are. Are they kind of oriented this way? Like, yeah, they are. But how does it look, right? What does the user see? So the real sweet spot is really visual-based applications because I don't think there's other great solutions for them out there. But in general, being a kind of generic visual testing application, it really applies to anything. Right on. For... A lot of web-based front ends, it's all Node.js based. Do you have a favorite Node.js type tool? Are you like a React fan or Next.js or Vue? Do you have a personal preference? Yes, I am a React fanboy for sure. I started, you know, we rewind all the way back to like the jQuery days and stuff. Right. I see that and I have nightmares still. We have some, we actually have some of that floating around in our like, like our admin applications and stuff where it's like a Rails backend and they're like, yeah, we got jQuery in there. And then my first thought is always like, well, like, how do you test that jQuery? And the answer is we don't. throw a couple rainforest tests at it and call it good um and I I started um I started with angular back in the day oh right on back angular one anyways was kind of the reverse of react we're like we're gonna put your javascript in your html rack took the approach and we're gonna put your html and your javascript you know just smush it all together um and it's come a very very long way I must say So yeah, I find working with React very easy and intuitive, and it's very nice that the general JavaScript community has supported that and has pushed that forward. Because especially with all software and technology, but especially in front-end development, it's really easy to pick the wrong tool long term. I pick this thing, it's great, and then we find a better way to do it, and they just abandon the project. This is true with anything open source, and we've run into this a lot of times, even with open source testing tools. Actually, we had a very large Enzyme test suite on our React application, and we ran into something like this. There was a new way of testing React apps, which was the React testing library. And Enzyme kind of said, yep, that's a better way to do it. We're going to stop supporting after a good version, like React, or React . I'm like, well, we want to upgrade to React . It's like, well, none of your Enzyme tests work. Yeah, exactly. Exactly. Too bad for us. And so now you start waiting the options of, well, how do we upgrade, right? Do we just say let's not upgrade, which is going to bite you really quickly, right? Especially at the pace all these JavaScript libraries are being updated. I want that new shiny thing. I want support for that thing. And I don't want to be stuck in the past. The more you get stuck in the past, the harder it is to catch up with everything else, right? And so our options were basically rewrite all these however many thousand enzyme tests. Or we could just nuke them all, which is, it reminds me of these memes I see about junior engineers and the intern, where their commit message is, I nuked all the tests because they were failing and I couldn't make them pass. Return true in all the tests because, yeah, it's one of the past. The only reasonable way to do things. Yeah. And and it sounds kind of like an overreaction. But as we started to kind of think about these testing philosophies, we're like, we have end to end test coverage on all of these things. Right. And a lot of the front end tests, even though they're unit tests, they they load things in a headless browser and we're kind of recreating what an end-to-end test does. So we chose to keep all of our actual unit tests, all the kind of business logic that didn't use Enzyme, nuke all the Enzyme tests and just lean into a Rainforest test because we know if the Rainforest tests are passing, we don't need all of these redundant tests anymore and instant productivity boost. Like I don't have to maintain all of these things anymore. I don't have to upgrade them. I could just get them out of my way and I can upgrade all my dependencies. And because we have really good end-to-end test coverage, we could do that confidently and know that we're not breaking things. So yeah, choosing dependencies can be quite tricky sometimes, especially in the JavaScript world. Did you find some places that you still wanted to reintroduce some of the React testing library for, I don't know, component level testing of the UI, or have you kept with like a hundred percent of the decision to not have that layer of testing anymore regarding the UI components because you focus on the full picture and then testing for the user flow and also whatever you have with the interaction with the backend? Yeah, we still have some of it, and we drew the line at user interactions, right? So React has this idea of hooks, which are basically just chunks of logic. It's just a function that I can use inside of a component. We stopped having any React testing library tests that were actual user interactions, no clicking on things, and instead we used it to test the functionality, the logic of those hooks. it's essentially a unit test but it's testing a specific react thing and it requires the the testing library to do that everything else kind of gets hoisted up to the end-to-end testing level and it's nice to just say hey designer hey product manager like go at this test coverage while I'm busy hacking on things and I don't have to worry about this anymore so that's actually um go ahead jillian Oh, I was just gonna say I'm so impressed with people who can keep up with like the UI and JavaScript plan because I've tried. I've tried like a few times and it just it then everything changed. I was like, alright, I'm not doing this anymore. I'm gonna go. I'm gonna go do high performance computing that hasn't changed in like thirty years. It's gonna be hard. Yeah, you definitely start feeling like Sisyphus. You're just pushing that rock up the hill. And every time you get to the top, someone tells you that you're actually on the wrong hill. I was going to say that seems like a really interesting approach that I hadn't thought of when we initially started talking, but you can replace having to write a lot of your tests in your React app by using Rainforest, by just focusing on what the end user experience is and testing for that, you can save yourself from having to write a lot of tests in the React standard library. So that's where the trade-off is though, right? Because these tests then are testing more functionality at once. And so if there is a problem, you don't necessarily know like which line of code is causing the issue or what interaction there is. you know there really is like how valuable is that flow I think and that's something that as you pointed out aj like you sort of have to determine up front like where is the value of your testing and how do you get the most value out of which pieces you're adding and where you're validating it etc and so yeah I mean in your case the ends the enzyme tests weren't actually providing the right value in the first place um so definitely switch them over Yeah, absolutely. And it's kind of a question of redundancy too, right? Like, is redundancy good? Sometimes. Like, I can be really, really sure and I can have some extra confidence that the thing isn't going to break. But most of the time, it just slows us down, right? I find that the... often the best time to add more unit test coverage is when something breaks, right? Because if my end-to-end tests are all passing, but something's broken, very often it's some kind of edge case, right? It's either some weird user behavior, some weird input, some weird sequence of events. And those things are usually better captured in a unit test because it's easier to kind of implement that specific scenario, that specific line of code that is the offender here versus creating a whole new end-to-end test to just cover some edge case. Those tests are going to just get longer and longer and just be... kind of confusing, honestly. It's like, well, why am I just like clicking in all of these random spots, doing these things, trying to cover these edge cases? Like just write a unit test for it and call it good. I really like the emphasis on, you know, testing for business logic and just in general having Not everything controlled by the engineers, because I find for myself, you know, like I'll write something and then I'll hand it off to a user and then they immediately start using it in some way that I didn't even think of. And that, you know, and then we do like a couple rounds of this. So being able to cut back on that person who writes thing who does not actually use the thing and then just immediately being able to push it off to an end user. Yeah, absolutely. Yeah. And things like testing and staging environments are great for this. We push code to those environments all the time, give them to a PM and say, go run and try and break this thing, right? Don't always want to do that in production, right? Like if the thing's not fully baked, I don't want to correct something in the database or whatever. And so having places to push that and have people early in the process iterating on this Finding the major bugs, the minor bugs, the stylistic bugs is super, super valuable than having one of your users find it later. Right on. So you live in Tahoe. Do you get outdoors a lot? I do. I live here with my wife and my dog. He's a lab husky mix. So he kind of thrives in the summer, thrives in the winter. There's lots of snow out right now. And so we're outside pretty much every day, snowboarding, hiking, kayaking, all that kind of stuff. Right on. How long have you lived in the Tahoe area? Um, I've been here for about five years now. I, uh, I grew up in the San Francisco Bay area and I was part of the great COVID migration out here. Uh, we always wanted to get here eventually. And, uh, I was lucky. Uh, I was still working at Rainforest at the time and already remote. So the transfer up here to, from remote, uh, near an office to remote, it actually doesn't matter how far you are from the office was very easy. And we're also real fortunate that we were not the only ones doing this migration. So we've made lots of friends that were like, yeah, we live down the street from you in the city and we all live here now. So it's a very different life, but we love it. And I don't think we're ever leaving. Ah, that's cool. Yeah. Right on. Tahoe is a beautiful area. Yeah, it really is. Cool. All right. Should we move on to some picks? Before we do, any final thoughts on QA, rainforest tips, guidance that you want to leave us with, AJ? I think just recapping is finding the balance between confidence and velocity, right? Everybody needs to set their own bar for quality. What is my ratio between confidence and velocity? Determining that for yourself is the most important thing here. And keeping in mind that not only is it velocity, but a lot of times it's the sanity of your engineers. We don't want to spend all of our time writing tests. So finding that balance and doing things in an efficient way is the key to success. Right on. And I think that's very use case specific too, you know, because the right answer for a financial app is going to be very different than the right answer for like a social media app. Absolutely. Cool. All right, Jillian, calling you out first. What'd you bring for a pick today? I am going to pick Drive by Dave Kellett. It is a sci-fi graphic novel and I think it's on its... I think it's like releasing the fourth one this summer, but it's so good. And it's so nice and wholesome, which is very nice because like, I really like sci-fi, but I don't really like violence or gore or, you know, icky fluids or just, I don't like any of that. Okay. I don't like any of it. And this is just so wholesome and adorable. And the main character is very cute. So that's it. That's the pick. got a whole bunch of copies for christmas and I'm like making people read them and I'm gonna I'm gonna have like a little little indie graphic novel cult going on soon enough great right on all right warren what'd you bring uh yeah so I just got back from a long hiatus being away from the show. I was on vacation. And so I think this pick is really accurate. Very short book. Highly recommend Tao Te Ching by Lao Tzu, which is the founder of Taoism, spelled Taoism, in case in case you've seen it written but never pronounced before. And there's just so much good stuff that is in the book that can be applied to everyday life, working environment, et cetera. It's incredibly short. There's only like a hundred and eight principles or so. And it starts off great with the Tao that can be told is not the eternal Tao. Like you can't write down the whole truth. There's something that's never said. It's impossible to convey everything. And I know it sounds so philosophical to go down this path, but I feel like going through these really helps to put into perspective thinking outside the box with solving certain problems or interactions or the communication we have every day. Highly recommend. Right on. Cool. AJ, what you got for us? Yeah, my reading and listening choices are kind of all over the map, but I did have an interesting one recently. It was called The Light Eaters. It's about plants and specifically this idea of plant intelligence. So obviously intelligence is a loaded word. They're not intelligent like you and I. They're not debating QA strategies and things like that, but they do have a lot of intelligent-like behavior. They communicate. They recognize their kin and They hear sounds, they transform themselves based on the visual appearance of the environment around them. And so I found it really interesting and gave me a lot to think about, especially when I'm out in nature with the wife and dog, just kind of staring at trees and stuff. um so yeah check it out no plants are intelligent for sure a hundred percent totally with you there's a there's a good one if you are out and there's plants or grass being cut and you notice the smell of you know freshly cut grass what is that it's a fear um intensely a fear pheromone that's been sent off to warn other grass that that there is danger around like that is the sign of intelligent life Yeah, for sure. There's lots of super interesting examples in this book and just like plants acting like animals essentially. And it's kind of a mind blowing experience. I read a book recently and I can't remember which one it was, but I've been studying mushrooms a lot lately and this book, showed where mushrooms actually act as a communication agent for trees in the forest. And so like a specific set of insects can start attacking trees on one end of the forest. And then the mushroom, because it's the mycelium that grows underneath the entire forest floor, will relay that information to the other trees in the forest. And so by the time the insects work their way down to those trees, that those trees are producing a scent or a pheromone that actually repels the insects by the time they get there. And I thought that was super cool. That is cool. I'm in on like a mushroom and foraging Facebook group. And everybody just like takes pictures of fun mushrooms that they find when they're out and about. And it's just such a nice little group because it's so chill. That's it. There's like, there's no drama. There's no nothing. It's just look at this mushroom I found. There's an app called iNaturalist that I use for that. You can take a picture of not just mushrooms, but anything you find that you can identify and then upload it to iNaturalist. And it will try to auto detect what it is for you, but then other people will come in and confirm or tell you what that actually is. That was pretty cool. I used to do that a lot as a kid. I'd have like the field guides and go out with my field guide and try to like identify all the plants. But now we have an app for that. There's an app for that. Always. Will, what's your pick? My pick is there's a series on Netflix called Kunk on Earth, and I thought my sense of humor was really, really dry, but this lady takes it to a whole new level. This series is just hilarious because she sits down. It's like the history of Earth, basically, but she'll sit down with legitimate world renowned experts in their field and ask them the most off the wall questions and that to me the hot was the highlight of the series is just the looks on their faces when she would ask them these questions that had absolutely nothing to do with what they were an expert in but super entertaining series definitely ten out of ten stars kunk on earth on netflix a hundred percent and you know there's actually two other things there's kunk on um uh britain I think and then there's like one on christmas and shakespeare so you have some episodes too oh sweet I will have to check those out because I love her sense of humor all right I've never heard that that's fun yeah it's very very accurate all right That brings us to the end of the episode. Thank you everyone for listening. Jillian, Warren, thank you for joining me hosting the show. And AJ, thanks for coming on the show, man. It's been a pleasure talking to you. Thanks so much for having me. It was a lot of fun. Right on. Glad to hear that. And I will see everyone next week.